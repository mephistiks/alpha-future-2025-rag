# alpha-future-2025-rag

## Суть задачи

Нужно разработать генеративный модуль для RAG-системы (Retrieval-Augmented Generation). Система принимает вопрос пользователя и найденные документы из retrieval-части, затем генерирует связный, точный и полезный ответ.

## Что нужно сделать

* Генерация: спроектировать архитектуру, формирующую ответ строго на основе найденных фрагментов корпуса.
* Пайплайн: объединить Retrieval (поиск) и Generation (генерацию) в единый pipeline: retrieval -> grounding -> generation.
* Качество: минимизировать галлюцинации; при отсутствии релевантной информации корректно обрабатывать ситуацию.
* Стек: допускаются любые Open Source модели.

## Технические ограничения (важно)

* Железо: решение должно запускаться локально на 1 GPU T4, 32 vCPU, 128 GB RAM.
* Модели: предпочтительны квантованные модели среднего размера из-за ограниченной видеопамяти.
* Запреты:
  * Никаких внешних API (OpenAI, Claude и т.д.) — только локальный инференс.
  * Никаких закрытых или платных лицензий.
  * Использование дополнительных данных запрещено.

## Данные

Даны три файла:

* `questions.csv`: q_id, query — запросы пользователей.
* `websites.csv`: web_id, web — база знаний (тексты с сайтов) для поиска.
* `answers.csv`: perfect_answer — эталонные ответы. Они приведены для понимания стиля и детализации; копирование запрещено, необходимо генерировать ответы на основе контекста.

## Метрика оценки: Recall-L

Метрика сочетает точность смысла и штраф за длину.

* Основа: BERTScore Recall (семантическая близость к эталону).
* Штраф за длину L(q):
  * Если ответ не превышает длину эталона более чем в 1.5 раза, штрафа нет.
  * Если ответ длиннее эталона от 1.5 до 3 раз, баллы линейно снижаются.
  * Если ответ длиннее эталона в 3 раза и более, оценка 0.

## Результат

Итоговое решение загружается в формате `submit.csv`. 