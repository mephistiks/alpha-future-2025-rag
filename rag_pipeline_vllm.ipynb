{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0128bde6",
   "metadata": {},
   "source": [
    "## 0. üì¶ –£—Å—Ç–∞–Ω–æ–≤–∫–∞ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–µ–π"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "install_deps",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy pandas torch tqdm\n",
    "!pip install llama-index llama-index-embeddings-huggingface\n",
    "!pip install llama-index-llms-openai-like llama-index-vector-stores-faiss\n",
    "!pip install faiss-cpu nest-asyncio httpx openai\n",
    "!pip install vllm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vllm_section",
   "metadata": {},
   "source": [
    "## 0.1 üöÄ –ó–∞–ø—É—Å–∫ vLLM —Å–µ—Ä–≤–µ—Ä–∞\n",
    "\n",
    "–ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º notebook –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø—É—Å—Ç–∏—Ç—å vLLM —Å–µ—Ä–≤–µ—Ä –≤ –æ—Ç–¥–µ–ª—å–Ω–æ–º —Ç–µ—Ä–º–∏–Ω–∞–ª–µ\n",
    "\n",
    "\n",
    "**–ö–æ–º–∞–Ω–¥–∞ –¥–ª—è –∑–∞–ø—É—Å–∫–∞**\n",
    "```bash\n",
    "vllm serve Qwen/Qwen2.5-7B-Instruct \\\n",
    "    --host 0.0.0.0 \\\n",
    "    --port 8000 \\\n",
    "    --dtype auto \\\n",
    "    --gpu-memory-utilization 0.9\n",
    "```\n",
    "\n",
    "**–ü–∞—Ä–∞–º–µ—Ç—Ä—ã:**\n",
    "- `--host 0.0.0.0` ‚Äî —Å–ª—É—à–∞—Ç—å –Ω–∞ –≤—Å–µ—Ö –∏–Ω—Ç–µ—Ä—Ñ–µ–π—Å–∞—Ö\n",
    "- `--port 8000` ‚Äî –ø–æ—Ä—Ç —Å–µ—Ä–≤–µ—Ä–∞ (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 8000)\n",
    "- `--dtype auto` ‚Äî –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏–π –≤—ã–±–æ—Ä —Ç–∏–ø–∞ –¥–∞–Ω–Ω—ã—Ö (float16/bfloat16)\n",
    "- `--gpu-memory-utilization 0.9` ‚Äî –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ 90% GPU –ø–∞–º—è—Ç–∏\n",
    "\n",
    "\n",
    "–°–µ—Ä–≤–µ—Ä –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É `http://localhost:8000/v1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "config_section",
   "metadata": {},
   "source": [
    "## 1. üîß –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –∏ –ò–º–ø–æ—Ä—Ç—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3962e775",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "QUESTIONS_PATH = \"data/questions.csv\"\n",
    "WEBSITES_PATH = \"data/websites.csv\"\n",
    "FAISS_INDEX_PATH = \"data/faiss_index\"\n",
    "\n",
    "# vLLM Server\n",
    "VLLM_BASE_URL = \"http://localhost:8000/v1\"\n",
    "LLM_MODEL = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "TOP_K = 7\n",
    "EMBEDDING_MODEL = \"intfloat/multilingual-e5-large\"\n",
    "\n",
    "BREAKPOINT_PERCENTILE = 85\n",
    "BUFFER_SIZE = 1\n",
    "\n",
    "MAX_TOKENS = 200\n",
    "TEMPERATURE = 0.1\n",
    "BATCH_SIZE = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d18af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from typing import List, Dict, Any, Optional\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from llama_index.core import Document, VectorStoreIndex, Settings, StorageContext\n",
    "from llama_index.core.node_parser import SemanticSplitterNodeParser, SentenceSplitter\n",
    "from llama_index.core.schema import TextNode\n",
    "from llama_index.core.prompts import PromptTemplate\n",
    "from llama_index.core.query_engine import RetrieverQueryEngine\n",
    "from llama_index.core.response_synthesizers import get_response_synthesizer\n",
    "\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from llama_index.llms.openai_like import OpenAILike\n",
    "from llama_index.vector_stores.faiss import FaissVectorStore\n",
    "import faiss\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b37b38",
   "metadata": {},
   "source": [
    "## 2. üìä –ó–∞–≥—Ä—É–∑–∫–∞ –∏ –ü—Ä–µ–¥–æ–±—Ä–∞–±–æ—Ç–∫–∞ –î–∞–Ω–Ω—ã—Ö"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c8a9de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(questions_path: str, websites_path: str) -> tuple:\n",
    "    \"\"\"–ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —Å –∞–≤—Ç–æ–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ–º —Ä–∞–∑–¥–µ–ª–∏—Ç–µ–ª—è\"\"\"\n",
    "    try:\n",
    "        df_websites = pd.read_csv(websites_path)\n",
    "        if len(df_websites.columns) == 1:\n",
    "            df_websites = pd.read_csv(websites_path, sep=';')\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"–û—à–∏–±–∫–∞ —á—Ç–µ–Ω–∏—è websites: {e}\")\n",
    "    \n",
    "    df_questions = pd.read_csv(questions_path)\n",
    "    \n",
    "    df_websites.columns = df_websites.columns.str.strip()\n",
    "    df_questions.columns = df_questions.columns.str.strip()\n",
    "    \n",
    "    return df_websites, df_questions\n",
    "\n",
    "df_websites, df_questions = load_data(QUESTIONS_PATH, WEBSITES_PATH)\n",
    "\n",
    "print(f\"Websites: {len(df_websites)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤\")\n",
    "print(f\"Questions: {len(df_questions)} –≤–æ–ø—Ä–æ—Å–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64faaa58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"–ü—Ä–∏–º–µ—Ä –¥–æ–∫—É–º–µ–Ω—Ç–∞ (websites):\")\n",
    "print(df_websites.iloc[0])\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\n–ü–µ—Ä–≤—ã–µ 5 –≤–æ–ø—Ä–æ—Å–æ–≤:\")\n",
    "print(df_questions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15d239",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text: str) -> str:\n",
    "    \"\"\"–ë–∞–∑–æ–≤–∞—è –æ—á–∏—Å—Ç–∫–∞ —Ç–µ–∫—Å—Ç–∞\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text)\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    text = text.strip()\n",
    "    return text\n",
    "\n",
    "text_col = None\n",
    "for col in ['text', 'web', 'content', 'body', 'page_content']:\n",
    "    if col in df_websites.columns:\n",
    "        text_col = col\n",
    "        break\n",
    "\n",
    "if text_col is None:\n",
    "    raise KeyError(f\"–ù–µ –Ω–∞–π–¥–µ–Ω–∞ –∫–æ–ª–æ–Ω–∫–∞ —Å —Ç–µ–∫—Å—Ç–æ–º! –î–æ—Å—Ç—É–ø–Ω—ã–µ: {list(df_websites.columns)}\")\n",
    "\n",
    "df_websites['clean_text'] = df_websites[text_col].apply(preprocess_text)\n",
    "\n",
    "text_lengths = df_websites['clean_text'].str.len()\n",
    "print(f\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –¥–ª–∏–Ω—ã —Ç–µ–∫—Å—Ç–æ–≤: Min={text_lengths.min()}, Max={text_lengths.max()}, Mean={text_lengths.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "020f75ab",
   "metadata": {},
   "source": [
    "## 3. üß† Semantic Chunking —Å LlamaIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5488cc5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"–ó–∞–≥—Ä—É–∑–∫–∞ embedding –º–æ–¥–µ–ª–∏: {EMBEDDING_MODEL}...\")\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(\n",
    "    model_name=EMBEDDING_MODEL,\n",
    "    device=device,\n",
    "    embed_batch_size=32,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "test_embedding = embed_model.get_text_embedding(\"–¢–µ—Å—Ç–æ–≤–∞—è —Å—Ç—Ä–æ–∫–∞ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏\")\n",
    "print(f\"Embedding –º–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞. –†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {len(test_embedding)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8afb0d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_documents(df: pd.DataFrame) -> List[Document]:\n",
    "    \"\"\"–°–æ–∑–¥–∞–Ω–∏–µ LlamaIndex –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ DataFrame\"\"\"\n",
    "    documents = []\n",
    "    \n",
    "    for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Creating documents\"):\n",
    "        text = row['clean_text']\n",
    "        \n",
    "        if len(text) < 50:\n",
    "            continue\n",
    "        \n",
    "        metadata = {}\n",
    "        if 'web_id' in row:\n",
    "            metadata['web_id'] = str(row['web_id'])\n",
    "        if 'url' in row:\n",
    "            metadata['url'] = str(row['url'])\n",
    "        if 'title' in row:\n",
    "            metadata['title'] = str(row['title'])\n",
    "        \n",
    "        doc = Document(\n",
    "            text=text,\n",
    "            metadata=metadata,\n",
    "            id_=str(row.get('web_id', idx))\n",
    "        )\n",
    "        documents.append(doc)\n",
    "    \n",
    "    return documents\n",
    "\n",
    "documents = create_documents(df_websites)\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –∏–∑ {len(df_websites)} –∑–∞–ø–∏—Å–µ–π\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e69bd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"–ó–∞–ø—É—Å–∫ Semantic Chunking (breakpoint={BREAKPOINT_PERCENTILE}, buffer={BUFFER_SIZE})...\")\n",
    "\n",
    "semantic_splitter = SemanticSplitterNodeParser(\n",
    "    embed_model=embed_model,\n",
    "    breakpoint_percentile_threshold=BREAKPOINT_PERCENTILE,\n",
    "    buffer_size=BUFFER_SIZE,\n",
    ")\n",
    "\n",
    "sentence_splitter = SentenceSplitter(\n",
    "    chunk_size=1024,\n",
    "    chunk_overlap=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0be97b3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nodes = []\n",
    "failed_docs = []\n",
    "CHUNK_BATCH_SIZE = 100\n",
    "\n",
    "print(f\"–û–±—Ä–∞–±–æ—Ç–∫–∞ {len(documents)} –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤...\")\n",
    "\n",
    "for i in tqdm(range(0, len(documents), CHUNK_BATCH_SIZE), desc=\"Chunking batches\"):\n",
    "    batch = documents[i:i + CHUNK_BATCH_SIZE]\n",
    "    \n",
    "    for doc in batch:\n",
    "        try:\n",
    "            if len(doc.text) > 200:\n",
    "                nodes = semantic_splitter.get_nodes_from_documents([doc])\n",
    "            else:\n",
    "                nodes = [TextNode(text=doc.text, metadata=doc.metadata)]\n",
    "            \n",
    "            if not nodes:\n",
    "                nodes = sentence_splitter.get_nodes_from_documents([doc])\n",
    "            \n",
    "            all_nodes.extend(nodes)\n",
    "            \n",
    "        except Exception as e:\n",
    "            try:\n",
    "                nodes = sentence_splitter.get_nodes_from_documents([doc])\n",
    "                all_nodes.extend(nodes)\n",
    "            except Exception as e2:\n",
    "                failed_docs.append((doc.id_, str(e2)))\n",
    "\n",
    "print(f\"–°–æ–∑–¥–∞–Ω–æ {len(all_nodes)} —á–∞–Ω–∫–æ–≤, –æ—à–∏–±–æ–∫: {len(failed_docs)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e1c1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunk_lengths = [len(node.text) for node in all_nodes]\n",
    "\n",
    "print(f\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —á–∞–Ω–∫–æ–≤: –í—Å–µ–≥–æ={len(all_nodes)}, Min={min(chunk_lengths)}, Max={max(chunk_lengths)}, Mean={np.mean(chunk_lengths):.0f}\")\n",
    "print(f\"\\n–ü—Ä–∏–º–µ—Ä —á–∞–Ω–∫–∞:\\n{all_nodes[0].text[:500]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299edcd9",
   "metadata": {},
   "source": [
    "## 4. üóÇÔ∏è –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ FAISS –ò–Ω–¥–µ–∫—Å–∞"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b65fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ FAISS –∏–Ω–¥–µ–∫—Å–∞...\")\n",
    "\n",
    "d = len(embed_model.get_text_embedding(\"test\"))\n",
    "print(f\"–†–∞–∑–º–µ—Ä–Ω–æ—Å—Ç—å: {d}\")\n",
    "\n",
    "faiss_index = faiss.IndexFlatL2(d)\n",
    "vector_store = FaissVectorStore(faiss_index=faiss_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e915fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å–∞—Ü–∏—è {len(all_nodes)} —á–∞–Ω–∫–æ–≤...\")\n",
    "\n",
    "index = VectorStoreIndex(\n",
    "    nodes=all_nodes,\n",
    "    storage_context=storage_context,\n",
    "    embed_model=embed_model,\n",
    "    show_progress=True,\n",
    ")\n",
    "\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å –ø–æ—Å—Ç—Ä–æ–µ–Ω! –í—Å–µ–≥–æ –≤–µ–∫—Ç–æ—Ä–æ–≤: {faiss_index.ntotal}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799e0ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(FAISS_INDEX_PATH, exist_ok=True)\n",
    "index.storage_context.persist(persist_dir=FAISS_INDEX_PATH)\n",
    "print(f\"–ò–Ω–¥–µ–∫—Å —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {FAISS_INDEX_PATH}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d486cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = index.as_retriever(similarity_top_k=TOP_K)\n",
    "\n",
    "test_query = \"–ö–∞–∫ —É–∑–Ω–∞—Ç—å –ë–ò–ö –∏ —Ä–∞—Å—á—ë—Ç–Ω—ã–π —Å—á—ë—Ç?\"\n",
    "retrieved_nodes = retriever.retrieve(test_query)\n",
    "\n",
    "print(f\"–¢–µ—Å—Ç–æ–≤—ã–π –∑–∞–ø—Ä–æ—Å: '{test_query}'\")\n",
    "print(f\"–ù–∞–π–¥–µ–Ω–æ {len(retrieved_nodes)} —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã—Ö —á–∞–Ω–∫–æ–≤:\")\n",
    "\n",
    "for i, node in enumerate(retrieved_nodes, 1):\n",
    "    print(f\"\\n--- –ß–∞–Ω–∫ {i} (score: {node.score:.4f}) ---\")\n",
    "    print(node.text[:300] + \"...\" if len(node.text) > 300 else node.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7779c423",
   "metadata": {},
   "source": [
    "## 5. ü§ñ –ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM (vLLM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc8489c",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_FOLDER = \"llama_index_vllm\"\n",
    "OUTPUT_PATH = f\"data/{OUTPUT_FOLDER}/submit.csv\"\n",
    "FULL_OUTPUT_PATH = f\"data/{OUTPUT_FOLDER}/qa_full_dataset.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "check_vllm",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "try:\n",
    "    response = requests.get(f\"{VLLM_BASE_URL}/models\", timeout=5)\n",
    "    if response.status_code == 200:\n",
    "        models = response.json()\n",
    "        print(f\"vLLM —Å–µ—Ä–≤–µ—Ä –¥–æ—Å—Ç—É–ø–µ–Ω. –ú–æ–¥–µ–ª–∏: {[m['id'] for m in models['data']]}\")\n",
    "    else:\n",
    "        print(f\"vLLM —Å–µ—Ä–≤–µ—Ä –≤–µ—Ä–Ω—É–ª —Å—Ç–∞—Ç—É—Å {response.status_code}\")\n",
    "except requests.exceptions.ConnectionError:\n",
    "    print(f\"–û—à–∏–±–∫–∞: vLLM —Å–µ—Ä–≤–µ—Ä –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω –ø–æ –∞–¥—Ä–µ—Å—É {VLLM_BASE_URL}\")\n",
    "    print(\"–ó–∞–ø—É—Å—Ç–∏—Ç–µ —Å–µ—Ä–≤–µ—Ä –∫–æ–º–∞–Ω–¥–æ–π: vllm serve Qwen/Qwen2.5-7B-Instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7660ed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"–ù–∞—Å—Ç—Ä–æ–π–∫–∞ LLM: {LLM_MODEL} —á–µ—Ä–µ–∑ vLLM...\")\n",
    "\n",
    "llm = OpenAILike(\n",
    "    model=LLM_MODEL,\n",
    "    api_key=\"EMPTY\",\n",
    "    api_base=VLLM_BASE_URL,\n",
    "    temperature=TEMPERATURE,\n",
    "    max_tokens=MAX_TOKENS,\n",
    "    is_chat_model=True,\n",
    ")\n",
    "\n",
    "Settings.llm = llm\n",
    "\n",
    "test_response = llm.complete(\"–°–∫–∞–∂–∏ '—Ä–∞–±–æ—Ç–∞–µ—Ç' –µ—Å–ª–∏ —Ç—ã –º–µ–Ω—è —Å–ª—ã—à–∏—à—å.\")\n",
    "print(f\"LLM –æ—Ç–≤–µ—Ç: {test_response.text[:100]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e8350cd",
   "metadata": {},
   "source": [
    "## 6. üîó RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b89adfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "RAG_PROMPT = \"\"\"–¢—ã ‚Äî –ø–æ–º–æ—â–Ω–∏–∫ –±–∞–Ω–∫–∞ –ê–ª—å—Ñ–∞-–ë–∞–Ω–∫. –¢–≤–æ—è –∑–∞–¥–∞—á–∞ ‚Äî –ø–æ–º–æ—á—å –∫–ª–∏–µ–Ω—Ç—É, –∏—Å–ø–æ–ª—å–∑—É—è –∫–æ–Ω—Ç–µ–∫—Å—Ç.\n",
    "\n",
    "–ö–û–ù–¢–ï–ö–°–¢:\n",
    "{context_str}\n",
    "\n",
    "–û–ë–†–ê–©–ï–ù–ò–ï –ö–õ–ò–ï–ù–¢–ê: {query_str}\n",
    "\n",
    "–ü–†–ê–í–ò–õ–ê:\n",
    "1. –ï—Å–ª–∏ –∫–ª–∏–µ–Ω—Ç –æ–ø–∏—Å—ã–≤–∞–µ—Ç –ø—Ä–æ–±–ª–µ–º—É –∏–ª–∏ —Å–∏—Ç—É–∞—Ü–∏—é (–¥–∞–∂–µ –±–µ–∑ –≤–æ–ø—Ä–æ—Å–∞) ‚Äî –¥–∞–π —Å–æ–≤–µ—Ç –∫–∞–∫ –µ—ë —Ä–µ—à–∏—Ç—å.\n",
    "2. –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –æ –ª–∏—á–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (–±–∞–ª–∞–Ω—Å, –æ–ø–µ—Ä–∞—Ü–∏–∏, –ø–µ—Ä–µ–≤–æ–¥—ã –∫–ª–∏–µ–Ω—Ç–∞) ‚Äî –æ–±—ä—è—Å–Ω–∏ –≥–¥–µ –ø–æ—Å–º–æ—Ç—Ä–µ—Ç—å: –≤ –º–æ–±–∏–ª—å–Ω–æ–º –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–∏, –ª–∏—á–Ω–æ–º –∫–∞–±–∏–Ω–µ—Ç–µ –ê–ª—å—Ñ–∞-–û–Ω–ª–∞–π–Ω, –∏–ª–∏ –ø–æ–∑–≤–æ–Ω–∏–≤ –Ω–∞ –≥–æ—Ä—è—á—É—é –ª–∏–Ω–∏—é 8 800 200-00-00.\n",
    "3. –ò—Å–ø–æ–ª—å–∑—É–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞.\n",
    "4. –û—Ç–≤–µ—á–∞–π –∫—Ä–∞—Ç–∫–æ: 1-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è.\n",
    "5. –ù–ï –ø–∏—à–∏ \"–∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ\" ‚Äî –ª—É—á—à–µ –¥–∞–π –æ–±—â–∏–π —Å–æ–≤–µ—Ç –ø–æ —Ç–µ–º–µ.\n",
    "\n",
    "–û–¢–í–ï–¢:\"\"\"\n",
    "\n",
    "qa_prompt = PromptTemplate(RAG_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9960808",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_synthesizer = get_response_synthesizer(\n",
    "    llm=llm,\n",
    "    text_qa_template=qa_prompt,\n",
    "    response_mode=\"compact\",\n",
    ")\n",
    "\n",
    "query_engine = RetrieverQueryEngine(\n",
    "    retriever=retriever,\n",
    "    response_synthesizer=response_synthesizer,\n",
    ")\n",
    "\n",
    "print(\"Query Engine —Å–æ–∑–¥–∞–Ω\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c58f258e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    \"–ö–∞–∫ —É–∑–Ω–∞—Ç—å –ë–ò–ö –∏ —Ä–∞—Å—á—ë—Ç–Ω—ã–π —Å—á—ë—Ç?\",\n",
    "    \"–ù–µ –ø—Ä–∏—Ö–æ–¥–∏—Ç —Å–º—Å\",\n",
    "    \"–ß—Ç–æ —Ç–∞–∫–æ–µ –∫—ç—à–±—ç–∫?\",\n",
    "    \"–ö–∞–∫ –≤–æ–π—Ç–∏ –≤ –ê–ª—å—Ñ–∞-–û–Ω–ª–∞–π–Ω?\",\n",
    "]\n",
    "\n",
    "print(\"–¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ RAG Pipeline:\\n\")\n",
    "\n",
    "for query in test_queries:\n",
    "    response = query_engine.query(query)\n",
    "    print(f\"‚ùì {query}\")\n",
    "    print(f\"üí¨ {response.response}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e5bfa63",
   "metadata": {},
   "source": [
    "## 7. üöÄ –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –û—Ç–≤–µ—Ç–æ–≤ –Ω–∞ –í—Å–µ –í–æ–ø—Ä–æ—Å—ã"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e427c",
   "metadata": {},
   "outputs": [],
   "source": [
    "q_id_col = 'q_id' if 'q_id' in df_questions.columns else df_questions.columns[0]\n",
    "query_col = 'query' if 'query' in df_questions.columns else df_questions.columns[1]\n",
    "\n",
    "ids = df_questions[q_id_col].tolist()\n",
    "queries = df_questions[query_col].tolist()\n",
    "\n",
    "print(f\"–ü–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–æ {len(queries)} –≤–æ–ø—Ä–æ—Å–æ–≤\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb759d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import nest_asyncio\n",
    "import time\n",
    "from asyncio import Semaphore\n",
    "import httpx\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "BATCH_SIZE = 10\n",
    "MAX_CONCURRENT = 10\n",
    "RETRY_ATTEMPTS = 3\n",
    "RETRY_DELAY = 2\n",
    "TIMEOUT = 60\n",
    "\n",
    "\n",
    "async def process_single_query(q_id, query, query_engine, retry=RETRY_ATTEMPTS):\n",
    "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–¥–Ω–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞ —Å retry\"\"\"\n",
    "    for attempt in range(retry):\n",
    "        try:\n",
    "            response = await asyncio.wait_for(\n",
    "                query_engine.aquery(query),\n",
    "                timeout=TIMEOUT\n",
    "            )\n",
    "            answer = response.response.strip()\n",
    "            context = \"\\n\\n\".join([node.text for node in response.source_nodes])\n",
    "            \n",
    "            return {\n",
    "                \"id\": q_id,\n",
    "                \"question\": query,\n",
    "                \"context\": context,\n",
    "                \"answer\": answer,\n",
    "                \"error\": None\n",
    "            }\n",
    "        except asyncio.TimeoutError:\n",
    "            if attempt < retry - 1:\n",
    "                await asyncio.sleep(RETRY_DELAY * (attempt + 1))\n",
    "                continue\n",
    "            return {\n",
    "                \"id\": q_id,\n",
    "                \"question\": query,\n",
    "                \"context\": \"TIMEOUT\",\n",
    "                \"answer\": \"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.\",\n",
    "                \"error\": \"Timeout\"\n",
    "            }\n",
    "        except Exception as e:\n",
    "            if attempt < retry - 1:\n",
    "                await asyncio.sleep(RETRY_DELAY * (attempt + 1))\n",
    "                continue\n",
    "            return {\n",
    "                \"id\": q_id,\n",
    "                \"question\": query,\n",
    "                \"context\": \"ERROR\",\n",
    "                \"answer\": \"–ö —Å–æ–∂–∞–ª–µ–Ω–∏—é, –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ.\",\n",
    "                \"error\": str(e)[:100]\n",
    "            }\n",
    "\n",
    "\n",
    "async def process_batch(batch_ids, batch_queries, query_engine):\n",
    "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –±–∞—Ç—á–∞ –∑–∞–ø—Ä–æ—Å–æ–≤\"\"\"\n",
    "    tasks = [\n",
    "        process_single_query(q_id, query, query_engine)\n",
    "        for q_id, query in zip(batch_ids, batch_queries)\n",
    "    ]\n",
    "    return await asyncio.gather(*tasks)\n",
    "\n",
    "\n",
    "async def process_all_batched(ids, queries, query_engine):\n",
    "    \"\"\"–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—Å–µ—Ö –∑–∞–ø—Ä–æ—Å–æ–≤ –±–∞—Ç—á–∞–º–∏\"\"\"\n",
    "    all_results = []\n",
    "    total_batches = (len(ids) + BATCH_SIZE - 1) // BATCH_SIZE\n",
    "    \n",
    "    semaphore = Semaphore(MAX_CONCURRENT)\n",
    "    \n",
    "    async def process_batch_with_semaphore(batch_idx):\n",
    "        async with semaphore:\n",
    "            start_idx = batch_idx * BATCH_SIZE\n",
    "            end_idx = min(start_idx + BATCH_SIZE, len(ids))\n",
    "            batch_ids = ids[start_idx:end_idx]\n",
    "            batch_queries = queries[start_idx:end_idx]\n",
    "            \n",
    "            results = await process_batch(batch_ids, batch_queries, query_engine)\n",
    "            return list(results)\n",
    "    \n",
    "    tasks = [process_batch_with_semaphore(i) for i in range(total_batches)]\n",
    "    \n",
    "    for i, coro in enumerate(tqdm(asyncio.as_completed(tasks), total=total_batches, desc=\"Processing batches\")):\n",
    "        batch_results = await coro\n",
    "        all_results.extend(batch_results)\n",
    "        \n",
    "        if (i + 1) % 10 == 0:\n",
    "            await asyncio.sleep(0.5)\n",
    "    \n",
    "    return all_results\n",
    "\n",
    "\n",
    "print(f\"–ë–∞—Ç—á–µ–≤–∞—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è {len(queries)} –≤–æ–ø—Ä–æ—Å–æ–≤...\")\n",
    "print(f\"Batch size: {BATCH_SIZE}, Max concurrent: {MAX_CONCURRENT}, Timeout: {TIMEOUT}s\")\n",
    "\n",
    "start_time = time.time()\n",
    "all_results = asyncio.run(process_all_batched(ids, queries, query_engine))\n",
    "elapsed = time.time() - start_time\n",
    "\n",
    "print(f\"–í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è: {elapsed:.1f} —Å–µ–∫ ({elapsed/60:.1f} –º–∏–Ω)\")\n",
    "print(f\"–°–∫–æ—Ä–æ—Å—Ç—å: {len(queries)/elapsed:.1f} –∑–∞–ø—Ä–æ—Å–æ–≤/—Å–µ–∫\")\n",
    "\n",
    "all_results.sort(key=lambda x: x[\"id\"])\n",
    "\n",
    "results = [{\"q_id\": r[\"id\"], \"answer\": r[\"answer\"]} for r in all_results]\n",
    "full_data = [{\"q_id\": r[\"id\"], \"question\": r[\"question\"], \"context\": r[\"context\"], \"answer\": r[\"answer\"]} for r in all_results]\n",
    "\n",
    "errors = [r for r in all_results if r[\"error\"]]\n",
    "if errors:\n",
    "    print(f\"–û—à–∏–±–æ–∫: {len(errors)}\")\n",
    "\n",
    "print(f\"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(results)} –≤–æ–ø—Ä–æ—Å–æ–≤\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2723a4",
   "metadata": {},
   "source": [
    "## 8. üíæ –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –†–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae13347",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(os.path.dirname(OUTPUT_PATH), exist_ok=True)\n",
    "\n",
    "df_submit = pd.DataFrame(results)\n",
    "df_submit.to_csv(OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"Submission —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {OUTPUT_PATH}\")\n",
    "print(f\"–ó–∞–ø–∏—Å–µ–π: {len(df_submit)}\")\n",
    "print(df_submit.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2688c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.DataFrame(full_data)\n",
    "df_full.to_csv(FULL_OUTPUT_PATH, index=False)\n",
    "\n",
    "print(f\"–ü–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω: {FULL_OUTPUT_PATH}\")\n",
    "print(f\"–ó–∞–ø–∏—Å–µ–π: {len(df_full)}, –ö–æ–ª–æ–Ω–∫–∏: {list(df_full.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d082e6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "insufficient_count = df_submit['answer'].str.contains(\n",
    "    '–Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ|–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ', \n",
    "    case=False, \n",
    "    na=False\n",
    ").sum()\n",
    "\n",
    "answer_lengths = df_submit['answer'].str.len()\n",
    "\n",
    "print(f\"–°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤:\")\n",
    "print(f\"  –í—Å–µ–≥–æ: {len(df_submit)}\")\n",
    "print(f\"  '–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ': {insufficient_count} ({insufficient_count/len(df_submit)*100:.1f}%)\")\n",
    "print(f\"  –î–ª–∏–Ω–∞: Min={answer_lengths.min()}, Max={answer_lengths.max()}, Mean={answer_lengths.mean():.0f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb91a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"–°–ª—É—á–∞–π–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã –æ—Ç–≤–µ—Ç–æ–≤ –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏:\\n\")\n",
    "\n",
    "sample = df_full.sample(min(10, len(df_full)))\n",
    "\n",
    "for _, row in sample.iterrows():\n",
    "    print(f\"‚ùì {row['question']}\")\n",
    "    print(f\"üí¨ {row['answer']}\")\n",
    "    print(\"-\" * 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689c5b7e",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéâ –ì–æ—Ç–æ–≤–æ!\n",
    "\n",
    "–§–∞–π–ª—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã:\n",
    "- `data/llama_index_vllm/submit.csv` ‚Äî submission file\n",
    "- `data/llama_index_vllm/qa_full_dataset.csv` ‚Äî –ø–æ–ª–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º\n",
    "- `data/faiss_index/` ‚Äî —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω—ã–π –∏–Ω–¥–µ–∫—Å"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
